# Narrative Engine Configuration
# Copy this file to .env and fill in your values

# Choose your LLM provider: openai, anthropic, gemini, local
LLM_PROVIDER=openai

# OpenAI Configuration
OPENAI_API_KEY=your-openai-api-key-here
OPENAI_MODEL=gpt-4-turbo-preview

# Anthropic Configuration
ANTHROPIC_API_KEY=your-anthropic-api-key-here
ANTHROPIC_MODEL=claude-3-opus-20240229

# Gemini Configuration
GEMINI_API_KEY=your-gemini-api-key-here
GEMINI_MODEL=gemini-1.5-pro

# Local LLM Configuration (for Ollama)
LOCAL_LLM_URL=http://localhost:11434
LOCAL_MODEL=llama2

# Generation Parameters
LLM_TEMPERATURE=0.9
LLM_MAX_TOKENS=2000

# Content Settings
CONTENT_RATING=mature  # pg, teen, mature, explicit

# World Settings
DEFAULT_WORLD_ID=default
ENABLE_ROMANCE=true
ENABLE_COMBAT=true

# Server Settings
HOST=0.0.0.0
PORT=8000
RELOAD=true

# Redis Configuration (optional)
REDIS_URL=redis://localhost:6379/0